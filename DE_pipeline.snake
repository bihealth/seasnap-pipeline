## SeA-SnaP differential expression pipeline for RNA-seq analysis
## version: 0.9.5
## author: J.P.Pett (patrick.pett@bihealth.de)

#TODO: requested feature: different analyses (e.g. designs, sample sets) in one report -> options: modify config or merge reports
#TODO: functional annotation optional (per contrast), add to report only if generated

#TODO: update documentation: report generation, rule development, templates, pictures, run pipeline
#TODO: snippet list to README
#TODO: auto-check config values (branch patrick_dev)

import os, re, yaml, textwrap, pandas as pd
from collections import OrderedDict
from time import asctime, localtime, time
from pathlib import Path
from snakemake.utils import report, format as snakemake_format
from tools.pipeline_tools import DEPipelinePathHandler, ReportTool

yaml.add_representer(OrderedDict, lambda dumper, data: dumper.represent_dict(dict(data)))

SNAKEDIR  = Path(workflow.current_basedir)
SNAKEFILE = workflow.snakefile
SCRIPTDIR = str(SNAKEDIR / "external_scripts")

# assemble config
configfile: str(SNAKEDIR / "defaults" / "DE_config_defaults.yaml")
configfile: "DE_config.yaml"
if config["organism_defaults"]:
	configfile: str(SNAKEDIR / "defaults" / config["organism_defaults"])
	configfile: "DE_config.yaml"

# create path handler
pph = DEPipelinePathHandler(workflow)

# exclude symbols '.' and '/' from wildcards
wildcard_constraints: 
	sample="[^./]+",
	name  ="[^./]+"


R_SESSION_INFO = r"""
cat("########################### session info ############################","\n")
print(sessionInfo())
cat("#####################################################################","\n\n")
"""

onstart:
	# draw a dag
	dag_file = pph.file_path(step="pipeline_report", extension="rule_execution.png", contrast="all")
	os.makedirs(os.path.dirname(dag_file), exist_ok=True)
	shell("snakemake --quiet --snakefile {} --rulegraph | dot -Tpng > {}".format(SNAKEFILE, dag_file))
	# info about the pipeline run
	info_file = pph.file_path(step="pipeline_report", extension="summary.csv", contrast="all")
	os.makedirs(os.path.dirname(info_file), exist_ok=True)
	shell("snakemake --quiet --snakefile {} --summary | sed 's/\t/, /g' > {}".format(SNAKEFILE, info_file))
	# save merged config
	config_file = pph.file_path(step="pipeline_report", extension="yaml", contrast="all")
	with open(config_file, "w") as f: yaml.dump(config, f, default_flow_style=False)


##-------------------- starting point ----------------------------------------------------------------------

def get_inputs_all():
	#contrasts
	inputs = pph.expand_path(step="contrast", extension="rds")
	
	#functional annotation
	inputs.append(pph.expand_path(step = "goseq", extension = "go.rds")),
	inputs.append(pph.expand_path(step = "goseq", extension = "kegg.rds"))
	
	return inputs


shell("rm -f {}".format(pph.file_path(step="pipeline_report", extension="report.html", contrast="all")))

rule all:
	input:
		get_inputs_all(),
		pph.file_path("report", "Rmd", contrast = "all")
	output:
		html = pph.file_path(step="pipeline_report", extension="report.html", contrast="all")
	run:
		loctime = asctime(localtime(time()))
		rule_execution = pph.file_path("pipeline_report", "rule_execution.png", contrast="all")
		summary        = pph.file_path("pipeline_report", "summary.csv",        contrast="all")
		version_info   = pph.file_path("pipeline_report", "version_info.txt",   contrast="all")
		conda_info     = pph.file_path("pipeline_report", "conda_info.txt",     contrast="all")
		dag = rule_execution.split("/")[-1]
		shell("conda list > {}".format(version_info))
		shell("conda info > {}".format(conda_info))
		report("""
		=======================
		RNAseq mapping pipeline
		=======================
		
		**Finished: {loctime}**
		
		.. image:: {dag}
		
		File status at pipeline start:
		==============================
		
		.. csv-table::
			:file: {summary}
			
		Version info:
		=============
		
		.. include:: {version_info}
			:literal:
		
		Conda info:
		===========
		
		.. include:: {conda_info}
			:literal:
		
		""", output.html, graph = rule_execution, table = summary)
	

##-------------------- make TxDb -----------------------------------------------------------------------------

rule TxDb_from_GTF:
	""" make a TxDb object from GTF """
	input:
		gtf = config["organism"]["files"]["gtf"]
	output:
		pph.file_path(step = "TxDb_from_GTF", extension = "sqlite", contrast = "all")
	log:
		out = pph.file_path("TxDb_from_GTF", "output.log", contrast = "all", log=True)
	run:
		genus = config["organism"]["genus"]
		taxon = config["organism"]["taxon"]
		
		script = textwrap.dedent(r"""
		#----- import packages
		library(GenomicFeatures)
		
		{R_SESSION_INFO}
		
		#----- make transcript to gene table
		TxDb <- makeTxDbFromGFF("{input.gtf}", format="gtf", organism="{genus}", taxonomyId={taxon})
		
		#----- save Db
		saveDb(TxDb, "{output}")
		""")
		
		script_file = pph.log(log.out, snakemake_format(script), step="TxDb_from_GTF", extension="R", contrast = "all", **wildcards)
		shell("Rscript --vanilla '{script_file}' &>> '{log.out}'")


##-------------------- import -------------------------------------------------------------------------------

DESIGN = config["experiment"]["design_formula"]


rule import_gene_counts:
	""" collect count files (STAR) and build count matrix """
	input:
		samples = config["experiment"]["covariate_file"]["star"]
	output:
		pph.file_path("import_gene_counts", "rds", contrast = "all")
	log:
		out = pph.file_path("import_gene_counts", "output.log", contrast = "all", log=True)
	run:
		column_filter = "TRUE"
		if config["filters"]["experiment_whitelist"]:
			column_filter  = "&".join("is.element(samples${},{})".format( k, "c({})".format(",".join('"'+l+'"' for l in v)) ) 
								for k,v in config["filters"]["experiment_whitelist"].items())
		if config["filters"]["experiment_blacklist"]:
			column_filter += "&".join("!is.element(samples${},{})".format( k, "c({})".format(",".join('"'+l+'"' for l in v)) ) 
								for k,v in config["filters"]["experiment_blacklist"].items())
		level_list  = "list({})".format(",".join("{}=c({})".format( n, ",".join('"'+s+'"' for s in l) ) 
							for n,l in config["experiment"]["columns"].items()))
		
		script = textwrap.dedent(r"""
		#----- import packages
		library(DESeq2)
		
		{R_SESSION_INFO}
		
		#----- import data
		sample_df <- read.table("{input.samples}", header=TRUE)
		files     <- as.character(sample_df$filename); print(files)
		samples   <- as.character(sample_df$label)

		#----- merge count files from star
		df_list   <- lapply(1:length(files), function(i) as.data.frame(read.csv(files[i], skip=4, sep="\t", 
		                                                                        col.names=c("ID", samples[i]), check.names=FALSE)))
		count_dat <- Reduce(function(...) merge(..., all=TRUE, by="ID"), df_list); rownames(count_dat) <- count_dat$ID
		
		#----- change levels
		level_cols <- {level_list}
		for (col in names(level_cols)) {{
			sample_df[,col] <- factor(sample_df[,col], levels = level_cols[[col]])
		}}

		#----- import counts in DESeq2
		rownames(sample_df) <- sample_df$label; count_dat <- count_dat[, rownames(sample_df)]
		dds <- DESeqDataSetFromMatrix(countData = as.matrix(count_dat), colData = sample_df, design = {DESIGN})
		
		#----- save as rds
		saveRDS(dds, file="{output}")
		""")
		
		script_file = pph.log(log.out, snakemake_format(script), step="import_gene_counts", extension="R", contrast = "all", **wildcards)
		shell("Rscript --vanilla '{script_file}' &>> '{log.out}'")

rule import_featurecounts:
	""" collect count files (featurecounts) and build count matrix """
	input:
		samples = config["experiment"]["covariate_file"]["star"]
	output:
		pph.file_path("import_featurecounts", "rds", contrast = "all")
	log:
		out = pph.file_path("import_featurecounts", "output.log", contrast = "all", log=True)
	run:
		column_filter = "TRUE"
		if config["filters"]["experiment_whitelist"]:
			column_filter  = "&".join("is.element(samples${},{})".format( k, "c({})".format(",".join('"'+l+'"' for l in v)) ) 
								for k,v in config["filters"]["experiment_whitelist"].items())
		if config["filters"]["experiment_blacklist"]:
			column_filter += "&".join("!is.element(samples${},{})".format( k, "c({})".format(",".join('"'+l+'"' for l in v)) ) 
								for k,v in config["filters"]["experiment_blacklist"].items())
		level_list  = "list({})".format(",".join("{}=c({})".format( n, ",".join('"'+s+'"' for s in l) ) 
							for n,l in config["experiment"]["columns"].items()))
		
		script = textwrap.dedent(r"""
		#----- import packages
		library(DESeq2)
		
		{R_SESSION_INFO}
		
		#----- import data
		sample_df <- read.table("{input.samples}", header=TRUE)
		files     <- as.character(sample_df$filename); print(files)
		samples   <- as.character(sample_df$label)

		#----- merge count files from star
                read_fc <- function(fn, sn) read.csv(fn, comment="#", sep="\t", colClasses=c("character", rep("NULL", 5), "numeric"), 
                                                     col.names=c("ID", rep("dummy", 5), sn), check.names=FALSE)
		df_list   <- lapply(1:length(files), function(i) as.data.frame(read_fc(files[i], samples[i])))
		count_dat <- Reduce(function(...) merge(..., all=TRUE, by="ID"), df_list); rownames(count_dat) <- count_dat$ID
		
		#----- change levels
		level_cols <- {level_list}
		for (col in names(level_cols)) {{
			sample_df[,col] <- factor(sample_df[,col], levels = level_cols[[col]])
		}}

		#----- import counts in DESeq2
		rownames(sample_df) <- sample_df$label; count_dat <- count_dat[, rownames(sample_df)]
		dds <- DESeqDataSetFromMatrix(countData = as.matrix(count_dat), colData = sample_df, design = {DESIGN})
		
		#----- save as rds
		saveRDS(dds, file="{output}")
		""")
		
		script_file = pph.log(log.out, snakemake_format(script), step="import_featurecounts", extension="R", contrast = "all", **wildcards)
		shell("Rscript --vanilla '{script_file}' &>> '{log.out}'")
	
rule import_sf:
	""" collect sf files (Salmon) and build count matrix """
	input:
		txdb    = pph.file_path("TxDb_from_GTF", "sqlite", contrast = "all"),
		samples = config["experiment"]["covariate_file"]["salmon"]
	output:
		pph.file_path("import_sf", "rds", contrast = "all")
	log:
		out = pph.file_path("import_sf", "output.log", contrast = "all", log=True)
	run:
		column_filter = "TRUE"
		if config["filters"]["experiment_whitelist"]:
			column_filter  = "&".join("is.element(sample_df${},{})".format( k, "c({})".format(",".join('"'+l+'"' for l in v)) ) 
								for k,v in config["filters"]["experiment_whitelist"].items())
		if config["filters"]["experiment_blacklist"]:
			column_filter += "&".join("!is.element(sample_df${},{})".format( k, "c({})".format(",".join('"'+l+'"' for l in v)) ) 
								for k,v in config["filters"]["experiment_blacklist"].items())
		level_list = "list({})".format(",".join("{}=c({})".format( k, ",".join('"'+l+'"' for l in v) ) 
								for k,v in config["experiment"]["columns"].items()))
		
		script = textwrap.dedent(r"""
		#----- import packages
		library(DESeq2)
		library(tximport)
		library(readr)
		library(AnnotationDbi)
		
		{R_SESSION_INFO}
		
		#----- make transcript to gene table
		TxDb    <- loadDb(file = "{input.txdb}")
		k       <- keys(TxDb, keytype = "TXNAME")
		tx2gene <- select(TxDb, k, "GENEID", "TXNAME")
		
		#----- use tximport on input files
		sample_df  <- read.table("{input.samples}", header=TRUE)
		sample_df  <- sample_df[{column_filter},]
		files      <- as.character(sample_df$filename); print(files)
		txi        <- tximport(files, type = "salmon", tx2gene = tx2gene)
		
		#----- change levels
		level_cols <- {level_list}
		for (col in names(level_cols)) {{
			sample_df[,col] <- factor(sample_df[,col], levels = level_cols[[col]])
		}}
		
		#----- import txi in DESeq2
		dds <- DESeqDataSetFromTximport(txi, colData = sample_df, design = {DESIGN})
		
		#----- save as rds
		saveRDS(dds, file="{output}")
		""")
		script_file = pph.log(log.out, snakemake_format(script), step="import_sf", extension="R", contrast = "all", **wildcards)
		shell("Rscript --vanilla '{script_file}' &>> '{log.out}'")


##-------------------- DESeq2 -------------------------------------------------------------------------------

rule DESeq2:
	""" run DESeq2 on a count matrix """
	input:
		pph.choose_input(choice_name = "mapping", options = [
		dict(step = "import_gene_counts",   extension = "rds", contrast = "all"),
		dict(step = "import_featurecounts", extension = "rds", contrast = "all"),
		dict(step = "import_sf",            extension = "rds", contrast = "all")
		])
	output:
		dds       = pph.file_path("DESeq2", "deseq2.rds", contrast = "all"),
		rld_blind = pph.file_path("DESeq2", "rld.blind.rds", contrast = "all"),
		rld_model = pph.file_path("DESeq2", "rld.model.rds", contrast = "all"),
		rld_csv   = pph.file_path("DESeq2", "rld.model.csv", contrast = "all")
	log:
		out = pph.file_path("DESeq2", "output.log", contrast = "all", log=True)
	params:
		coef_names = pph.file_path("DESeq2", "coef_names.txt", contrast = "all"),
		rld_names  = pph.file_path("DESeq2", "rld.model.csv", contrast = "all"),
		annot_pkg  = config["organism"]["R"]["annotations"]
	run:
		count_threshold       = config["filters"]["low_counts"]
                normalized_expression = config["normalization"]["normalized_expression"]
		script = textwrap.dedent(r"""
		#----- import packages
		library(DESeq2)
		library(AnnotationDbi)
		library({params.annot_pkg})
		
		{R_SESSION_INFO}
		
		#----- load DESeqDataSet
		dds <- readRDS("{input}")
		
		#----- pre-filtering
		keep <- rowSums(counts(dds)) >= {count_threshold}
		dds  <- dds[keep,]
		
		#----- DESeq2
		dds <- DESeq(dds, betaPrior=FALSE, test="Wald")

		# ----- Normalised expression values
		rld_blind <- switch("{normalized_expression}",
			"rld"=rlog(dds, blind=TRUE),
			"vst"=vst(dds, blind=TRUE)
		)
		rld_model <- switch("{normalized_expression}",
			"rld"=rlog(dds, blind=FALSE),
			"vst"=vst(dds, blind=FALSE)
		)

		#----- save as rds
		saveRDS(dds, file="{output.dds}")
		saveRDS(rld_blind, file="{output.rld_blind}")
		saveRDS(rld_model, file="{output.rld_model}")

		#----- save other files
		writeLines(resultsNames(dds), "{params.coef_names}")
		write.table(data.frame(
			gene_id=rownames(rld_model),
			assays(rld_model),
			symbol=mapIds({params.annot_pkg}, keys=sub("\\.[0-9]+$", "", row.names(dds)), 
			              column="SYMBOL", keytype="ENSEMBL", multiVals="first"),
			entrez=mapIds({params.annot_pkg}, keys=sub("\\.[0-9]+$", "", row.names(dds)), 
			              column="SYMBOL", keytype="ENSEMBL", multiVals="first")
			), file="{output.rld_csv}", sep="\t", col.names=TRUE, row.names=FALSE, quote=FALSE)
		""")
		script_file = pph.log(log.out, snakemake_format(script), step="DESeq2", extension="R", contrast = "all", **wildcards)
		shell("Rscript --vanilla '{script_file}' &>> '{log.out}'")
		
		
##-------------------- contrasts ----------------------------------------------------------------------------

rule contrast:
	""" make a contrast """
	input:
		pph.file_path("DESeq2", "deseq2.rds", contrast = "all")
	output:
		rds = pph.file_path("contrast", "rds"),
		csv = pph.file_path("contrast", "csv")
	log:
		out           = pph.file_path("contrast", "output.log",  log=True),
		contrast_yaml = pph.file_path("contrast", "contrast.yaml", log=True)
	params:
		ma_plot    = pph.file_path("contrast", "ma.pdf"),
		count_plot = pph.file_path("contrast", "counts.pdf"),
		annot_pkg  = config["organism"]["R"]["annotations"]
	run:
		contrast = pph.get_contrast(wildcards.contrast)
		with open(log.contrast_yaml, "w") as f: yaml.dump(contrast, f, default_flow_style=False)
		
		# variants of contrast definition
		contrast_column, contrast_ref = "group", ""
		if "coef" in contrast:
			contrast_type          = "coef"
			arg_val                = '="{}"'.format(contrast["coef"])
			contrast_def, lfc_def  = "name" + arg_val, "coef" + arg_val
		elif "ratio" in contrast:
			contrast_type, ratio   = "ratio", contrast["ratio"]
			contrast_column, contrast_num, contrast_ref = ratio["column"], ratio["numerator"], ratio["denominator"]
			contrast_def = lfc_def = 'contrast=c("{}", "{}", "{}")'.format(contrast_column, contrast_num, contrast_ref)
		elif "vector" in contrast:
			contrast_type          = "vector"
			contrast_def = lfc_def = 'contrast=c({})'.format(", ".join(contrast["vector"]))
		else:
			raise ValueError("Error in contrast: no valid contrast definition! must be one of {}".format(["coef:", "ratio:", "vector:"]))
		
		# parameters
		cutoff_FDR           =           contrast["max_p_adj"]
		lfcThreshold         =           contrast["results_parameters"]["lfcThreshold"]
		altHypothesis        =           contrast["results_parameters"]["altHypothesis"]
		independentFiltering = "TRUE" if contrast["results_parameters"]["independentFiltering"] else "FALSE"
		lfc_shrink_type      =           contrast["lfcShrink_parameters"]["type"]
		rank_by              =           contrast["ranking_by"]
		rank_order           =           contrast["ranking_order"].replace("x", "res$"+rank_by)
		
		script = textwrap.dedent(r"""
		#----- import packages
		library(DESeq2)
		library(AnnotationDbi)
		library({params.annot_pkg})
		
		{R_SESSION_INFO}
		
		#----- load DESeqDataSet
		dds <- readRDS("{input}")
		
		#----- contrast
		if ("{contrast_type}" == "ratio") {{
			dds${contrast_column} = relevel(dds${contrast_column}, ref="{contrast_ref}")
			dds <- nbinomWaldTest(dds)
		}}
		res <- results(dds, {contrast_def}, alpha={cutoff_FDR}, lfcThreshold={lfcThreshold}, 
		               altHypothesis="{altHypothesis}", independentFiltering={independentFiltering})

		#----- log-fold-change shrinkage
		#res$lfcShrunk   <- res$log2FoldChange
		#res$lfcShrunkSE <- res$lfcSE
		if ("{lfc_shrink_type}"!="none"){{
			lfc <- lfcShrink(dds, {lfc_def}, lfcThreshold={lfcThreshold}, type="{lfc_shrink_type}")
			res$log2FoldChange_orig <- res$log2FoldChange
			res$log2FoldChange      <- lfc$log2FoldChange
			res$lfcSE_orig          <- res$lfcSE
			res$lfcSE               <- lfc$lfcSE
		}}
		
		#----- ranking
		res <- res[order({rank_order}),]
		
		#----- annotation [BEWARE- the in case on multiple mapping, the first entry will be selected]
		res$symbol <- mapIds({params.annot_pkg}, keys=sub("\\.[0-9]+$", "", row.names(res)), 
		                     column="SYMBOL", keytype="ENSEMBL", multiVals="first")
		res$entrez <- mapIds({params.annot_pkg}, keys=sub("\\.[0-9]+$", "", row.names(res)), 
		                     column="ENTREZID", keytype="ENSEMBL", multiVals="first")
		
		#----- save as rds & csv
		saveRDS(res, file="{output.rds}")
		write.table(data.frame(gene_id=rownames(res), res), file="{output.csv}", sep="\t", col.names=TRUE, row.names=FALSE, quote=FALSE)
		""")
		
		script_file = pph.log(log.out, snakemake_format(script), step="contrast", extension="R", **wildcards)
		shell("Rscript --vanilla '{script_file}' &>> '{log.out}'")


##-------------------- functional annotation ----------------------------------------------------------------

rule goseq:
	""" functional annotation with goseq producing GO and KEGG lists """
	input:
		txdb = pph.file_path("TxDb_from_GTF", "sqlite", contrast = "all"),
		res  = pph.file_path("contrast", "rds")
	output:
		go   = pph.file_path(step = "goseq", extension = "go.rds"),
		kegg = pph.file_path(step = "goseq", extension = "kegg.rds")
	log:
		out           = pph.file_path(step = "goseq", extension = "output.log",    log=True),
		contrast_yaml = pph.file_path(step = "goseq", extension = "contrast.yaml", log=True)
	params:
		annot_pkg = config["organism"]["R"]["annotations"],
		fit_pwf   = pph.file_path(step = "goseq", extension = "pwf_fit.pdf")
	run:
		contrast = pph.get_contrast(wildcards.contrast)
		with open(log.contrast_yaml, "w") as f: yaml.dump(contrast, f, default_flow_style=False)
		
		fdr_threshold = contrast["GO"]["fdr_threshold"]
		AnnotationDbi_prefix = ".".join(params.annot_pkg.split(".")[:-1])
		
		script = textwrap.dedent(r"""
		#----- import packages
		library(goseq)
		library(GenomicFeatures)
		library(AnnotationDbi)
		library({params.annot_pkg})
		
		{R_SESSION_INFO}
		
		#----- load results
		res <- readRDS("{input.res}")
		
		#----- vector for goseq
		assayed.genes <- rownames(res)
		de.genes <- assayed.genes[which(res$padj < {fdr_threshold})]
		gene.vector <- as.integer(assayed.genes %in% de.genes); names(gene.vector) <- assayed.genes
                names(gene.vector) <- sub("\\.[0-9]+", "", names(gene.vector))
		
		#----- get gene lengths
		TxDb <- loadDb(file = "{input.txdb}")
		lengthData <- median(width(transcriptsBy(TxDb, "gene")))[rownames(res)]; names(lengthData) <- rownames(res)
		
		#----- get GO mapping
		en2eg <- as.list({AnnotationDbi_prefix}ENSEMBL2EG); go2eg <- as.list({AnnotationDbi_prefix}GO2ALLEGS)
		eg2go <- split(rep(names(go2eg), lengths(go2eg)), unlist(go2eg)); eg2kegg <- as.list({AnnotationDbi_prefix}PATH)

		grepAnnot <- function(id,mapkeys) unique(unlist(mapkeys[id], use.names=FALSE))
		go <- lapply(en2eg, grepAnnot, eg2go); kegg <- lapply(en2eg, grepAnnot, eg2kegg)
		
		#----- run goseq
		pdf("{params.fit_pwf}")
		pwf <- nullp(gene.vector, bias.data=lengthData)
		dev.off()
		GO <- goseq(pwf, gene2cat=go)
		KEGG <- goseq(pwf, gene2cat=kegg)
		
		GO$over_represented_qvalue <- p.adjust(GO$over_represented_pvalue, method="BH")
		GO$under_represented_qvalue <- p.adjust(GO$under_represented_pvalue, method="BH")
		KEGG$over_represented_qvalue <- p.adjust(KEGG$over_represented_pvalue, method="BH")
		KEGG$under_represented_qvalue <- p.adjust(KEGG$under_represented_pvalue, method="BH")
		
		#----- save as rds
		saveRDS(GO, file="{output.go}"); saveRDS(KEGG, file="{output.kegg}")
		""")
		
		script_file = pph.log(log.out, snakemake_format(script), step="goseq", extension="R", **wildcards)
		shell("Rscript --vanilla '{script_file}' &>> '{log.out}'")

		
##-------------------- QC steps -----------------------------------------------------------------------------

# plots go into report snippets


##-------------------- report -------------------------------------------------------------------------------

rule report:
	""" write a static Rmd report """
	input:
		get_inputs_all()
	output:
		pph.file_path("report", "Rmd", contrast = "all")
	run:
		file_table  = pph.file_path("report", "tsv", contrast = "all")
		pph.log_generated_files(save_to = file_table)
		
		rt = ReportTool(config, id_dicts={"contrast": pph.get_contrast_id_dict()})
		report_text = rt.generate_report()
		
		# switch single and double braces
		report_text = report_text.replace("{","{{").replace("}","}}")
		report_text = report_text.replace("{{{{","{").replace("}}}}","}")
		
		# fill in wildcards
		report_wildcards  = re.findall("(?<!{){([^{}]+)}(?!})", report_text)
		format_dict = {}
		for rw in report_wildcards:
			parts = rw.split("-")
			if len(parts) == 2:
				format_dict[rw] = pph.file_path(parts[0], parts[1], contrast = "all")
			elif len(parts) == 3:
				format_dict[rw] = pph.file_path(parts[0], parts[1], contrast = parts[2])
			else:
				format_dict[rw] = "{" + rw + "}"
					
		format_dict["WORKING_DIRECTORY"] = os.getcwd() + os.sep
		format_dict["R_COMMON"]          = str(rt.report_snippet_base_dir/"R_common")
		format_dict["FILE_TABLE"]        = file_table
				
		report_text = report_text.format(**format_dict)
		report_text = report_text.replace("{{","{").replace("}}","}")
		
		with open(output[0], "w") as f:
			f.write(report_text)





