## SeA-SnaP differential expression pipeline for RNA-seq analysis
## version: 0.9.5
## author: J.P.Pett (patrick.pett@bihealth.de)

#TODO: continue documentation
#TODO: auto-check config values in pph


import os, re, yaml, textwrap, pandas as pd
from collections import OrderedDict
from time import asctime, localtime, time
from pathlib import Path
from snakemake.utils import report, R, format as snakemake_format
from tools.pipeline_tools import DEPipelinePathHandler, ReportTool

yaml.add_representer(OrderedDict, lambda dumper, data: dumper.represent_dict(dict(data)))


SNAKEDIR  = Path(workflow.current_basedir)
SNAKEFILE = workflow.snakefile
SCRIPTDIR = str(SNAKEDIR / "external_scripts")

# assemble config
configfile: str(SNAKEDIR / "defaults" / "DE_config_defaults.yaml")
configfile: "DE_config.yaml"
if config["organism_defaults"]:
	configfile: str(SNAKEDIR / "defaults" / config["organism_defaults"])
	configfile: "DE_config.yaml"

# create path handler
conf_ranges = str(SNAKEDIR / "defaults" / "DE_config_ranges.yaml")
test_config = conf_ranges if config["pipeline_param"]["test_config"] else None
pph = DEPipelinePathHandler(config, test_config)

# exclude symbols '.' and '/' from wildcards
wildcard_constraints: 
	sample="[^./]+",
	name  ="[^./]+"


R_SESSION_INFO = r"""
cat("########################### session info ############################","\n")
print(sessionInfo())
cat("#####################################################################","\n\n")
"""

onstart:
	# draw a dag
	dag_file = pph.file_path(step="pipeline_report", extension="rule_execution.png", contrast="all")
	os.makedirs(os.path.dirname(dag_file), exist_ok=True)
	shell("snakemake --quiet --snakefile {} --rulegraph | dot -Tpng > {}".format(SNAKEFILE, dag_file))
	# info about the pipeline run
	info_file = pph.file_path(step="pipeline_report", extension="summary.csv", contrast="all")
	os.makedirs(os.path.dirname(info_file), exist_ok=True)
	shell("snakemake --quiet --snakefile {} --summary | sed 's/\t/, /g' > {}".format(SNAKEFILE, info_file))
	# save merged config
	config_file = pph.file_path(step="pipeline_report", extension="yaml", contrast="all")
	with open(config_file, "w") as f: yaml.dump(config, f, default_flow_style=False)



##-------------------- starting point ----------------------------------------------------------------------

def get_inputs_all():
	#contrasts
	inputs = pph.expand_path(step="contrast", extension="rds")
	
	#functional annotation
	inputs.append(pph.expand_path(step = "goseq", extension = "go.rds")),
	inputs.append(pph.expand_path(step = "goseq", extension = "kegg.rds"))
	
	#QC
	if config["QC"]["countMatrix_heatmap"]["plot"]: 
		inputs.append(pph.file_path("countMatrix_heatmap", "pdf", contrast = "all"))
	if config["QC"]["sample_similarity"]["plot"]: 
		inputs.append(pph.file_path("sample_similarity",   "png", contrast = "all"))
	if config["QC"]["samples_pca"]["plot"]: 
		inputs.append(pph.file_path("samples_pca",         "pdf", contrast = "all"))
	return inputs


shell("rm -f {}".format(pph.file_path(step="pipeline_report", extension="report.html", contrast="all")))

rule all:
	input:
		get_inputs_all(),
		pph.file_path("report", "Rmd", contrast = "all")
	output:
		html = pph.file_path(step="pipeline_report", extension="report.html", contrast="all")
	run:
		loctime = asctime(localtime(time()))
		rule_execution = pph.file_path("pipeline_report", "rule_execution.png", contrast="all")
		summary        = pph.file_path("pipeline_report", "summary.csv",        contrast="all")
		version_info   = pph.file_path("pipeline_report", "version_info.txt",   contrast="all")
		conda_info     = pph.file_path("pipeline_report", "conda_info.txt",     contrast="all")
		dag = rule_execution.split("/")[-1]
		shell("conda list > {}".format(version_info))
		shell("conda info > {}".format(conda_info))
		report("""
		=======================
		RNAseq mapping pipeline
		=======================
		
		**Finished: {loctime}**
		
		.. image:: {dag}
		
		File status at pipeline start:
		==============================
		
		.. csv-table::
			:file: {summary}
			
		Version info:
		=============
		
		.. include:: {version_info}
			:literal:
		
		Conda info:
		===========
		
		.. include:: {conda_info}
			:literal:
		
		""", output.html, graph = rule_execution, table = summary)
	
##-------------------- make TxDb -----------------------------------------------------------------------------

rule TxDb_from_GTF:
	""" make a TxDb object from GTF """
	input:
		gtf = config["organism"]["files"]["gtf"]
	output:
		pph.file_path(step = "TxDb_from_GTF", extension = "sqlite", contrast = "all")
	log:
		r_script = pph.file_path(step = "TxDb_from_GTF", extension = "R",            log=True, contrast = "all"),
		r_output = pph.file_path(step = "TxDb_from_GTF", extension = "r_output.log", log=True, contrast = "all")
	run:
		genus = config["organism"]["genus"]
		taxon = config["organism"]["taxon"]
		
		script = textwrap.dedent(r"""
		#----- import packages
		library(GenomicFeatures)
		
		{R_SESSION_INFO}
		
		#----- make transcript to gene table
		TxDb <- makeTxDbFromGFF("{input.gtf}", format="gtf", organism="{genus}", taxonomyId={taxon})
		
		#----- save Db
		saveDb(TxDb, "{output}")
		""")
		with open(log.r_script, "w") as f: f.write(snakemake_format(script))
		
		shell("Rscript --vanilla '{log.r_script}' &> '{log.r_output}'")


##-------------------- import -------------------------------------------------------------------------------

DESIGN = config["experiment"]["design_formula"]


rule import_gene_counts:
	""" collect count files (STAR) and build count matrix """
	input:
		samples = config["experiment"]["covariate_file"]["star"]
	output:
		pph.file_path("import_gene_counts", "rds", contrast = "all")
	log:
		r_script = pph.file_path("import_gene_counts", "R",            contrast = "all", log=True),
		r_output = pph.file_path("import_gene_counts", "r_output.log", contrast = "all", log=True)
	run:
		column_filter = "TRUE"
		if config["filters"]["experiment_whitelist"]:
			column_filter  = "&".join("is.element(samples${},{})".format( k, "c({})".format(",".join('"'+l+'"' for l in v)) ) 
								for k,v in config["filters"]["experiment_whitelist"].items())
		if config["filters"]["experiment_blacklist"]:
			column_filter += "&".join("!is.element(samples${},{})".format( k, "c({})".format(",".join('"'+l+'"' for l in v)) ) 
								for k,v in config["filters"]["experiment_blacklist"].items())
		level_list  = "list({})".format(",".join("{}=c({})".format( n, ",".join('"'+s+'"' for s in l) ) 
							for n,l in config["experiment"]["columns"].items()))
		
		script = textwrap.dedent(r"""
		#----- import packages
		library(DESeq2)
		
		{R_SESSION_INFO}
		
		#----- import data
		sample_df <- read.table("{input.samples}", header=TRUE)
		files     <- as.character(sample_df$filename); print(files)
		samples   <- as.character(sample_df$label)

		#----- merge count files from star
		df_list   <- lapply(1:length(files), function(i) as.data.frame(read.csv(files[i], skip=4, sep="\t", col.names=c("ID", samples[i]), check.names=FALSE)))
		count_dat <- Reduce(function(...) merge(..., all=TRUE, by="ID"), df_list); rownames(count_dat) <- count_dat$ID
		
		#----- change levels
		level_cols <- {level_list}
		for (col in names(level_cols)) {{
			sample_df[,col] <- factor(sample_df[,col], levels = level_cols[[col]])
		}}

		#----- import counts in DESeq2
		rownames(sample_df) <- sample_df$label; count_dat <- count_dat[, rownames(sample_df)]
		dds <- DESeqDataSetFromMatrix(countData = as.matrix(count_dat), colData = sample_df, design = {DESIGN})
		
		#----- save as rds
		saveRDS(dds, file="{output}")
		""")
		
		with open(log.r_script, "w") as f: f.write(snakemake_format(script))
		shell("Rscript --vanilla '{log.r_script}' &> '{log.r_output}'")

rule import_featurecounts:
	""" collect count files (featurecounts) and build count matrix """
	input:
		samples = config["experiment"]["covariate_file"]["star"]
	output:
		pph.file_path("import_featurecounts", "rds", contrast = "all")
	log:
		r_script = pph.file_path("import_featurecounts", "R",            contrast = "all", log=True),
		r_output = pph.file_path("import_featurecounts", "r_output.log", contrast = "all", log=True)
	run:
		column_filter = "TRUE"
		if config["filters"]["experiment_whitelist"]:
			column_filter  = "&".join("is.element(samples${},{})".format( k, "c({})".format(",".join('"'+l+'"' for l in v)) ) 
								for k,v in config["filters"]["experiment_whitelist"].items())
		if config["filters"]["experiment_blacklist"]:
			column_filter += "&".join("!is.element(samples${},{})".format( k, "c({})".format(",".join('"'+l+'"' for l in v)) ) 
								for k,v in config["filters"]["experiment_blacklist"].items())
		level_list  = "list({})".format(",".join("{}=c({})".format( n, ",".join('"'+s+'"' for s in l) ) 
							for n,l in config["experiment"]["columns"].items()))
		
		script = textwrap.dedent(r"""
		#----- import packages
		library(DESeq2)
		
		{R_SESSION_INFO}
		
		#----- import data
		sample_df <- read.table("{input.samples}", header=TRUE)
		files     <- as.character(sample_df$filename); print(files)
		samples   <- as.character(sample_df$label)

		#----- merge count files from star
                read_fc <- function(fn, sn) read.csv(fn, comment="#", sep="\t", colClasses=c("character", rep("NULL", 5), "numeric"), col.names=c("ID", rep("dummy", 5), sn), check.names=FALSE)
		df_list   <- lapply(1:length(files), function(i) as.data.frame(read_fc(files[i], samples[i])))
		count_dat <- Reduce(function(...) merge(..., all=TRUE, by="ID"), df_list); rownames(count_dat) <- count_dat$ID
		
		#----- change levels
		level_cols <- {level_list}
		for (col in names(level_cols)) {{
			sample_df[,col] <- factor(sample_df[,col], levels = level_cols[[col]])
		}}

		#----- import counts in DESeq2
		rownames(sample_df) <- sample_df$label; count_dat <- count_dat[, rownames(sample_df)]
		dds <- DESeqDataSetFromMatrix(countData = as.matrix(count_dat), colData = sample_df, design = {DESIGN})
		
		#----- save as rds
		saveRDS(dds, file="{output}")
		""")
		
		with open(log.r_script, "w") as f: f.write(snakemake_format(script))
		shell("Rscript --vanilla '{log.r_script}' &> '{log.r_output}'")
	
rule import_sf:
	""" collect sf files (Salmon) and build count matrix """
	input:
		txdb    = pph.file_path("TxDb_from_GTF", "sqlite", contrast = "all"),
		samples = config["experiment"]["covariate_file"]["salmon"]
	output:
		pph.file_path("import_sf", "rds", contrast = "all")
	log:
		r_script = pph.file_path("import_sf", "R",            contrast = "all", log=True),
		r_output = pph.file_path("import_sf", "r_output.log", contrast = "all", log=True)
	run:
		column_filter = "TRUE"
		if config["filters"]["experiment_whitelist"]:
			column_filter  = "&".join("is.element(sample_df${},{})".format( k, "c({})".format(",".join('"'+l+'"' for l in v)) ) 
								for k,v in config["filters"]["experiment_whitelist"].items())
		if config["filters"]["experiment_blacklist"]:
			column_filter += "&".join("!is.element(sample_df${},{})".format( k, "c({})".format(",".join('"'+l+'"' for l in v)) ) 
								for k,v in config["filters"]["experiment_blacklist"].items())
		level_list = "list({})".format(",".join("{}=c({})".format( k, ",".join('"'+l+'"' for l in v) ) 
								for k,v in config["experiment"]["columns"].items()))
		
		script = textwrap.dedent(r"""
		#----- import packages
		library(DESeq2)
		library(tximport)
		library(readr)
		library(AnnotationDbi)
		
		{R_SESSION_INFO}
		
		#----- make transcript to gene table
		TxDb    <- loadDb(file = "{input.txdb}")
		k       <- keys(TxDb, keytype = "TXNAME")
		tx2gene <- select(TxDb, k, "GENEID", "TXNAME")
		
		#----- use tximport on input files
		sample_df  <- read.table("{input.samples}", header=TRUE)
		sample_df  <- sample_df[{column_filter},]
		files      <- as.character(sample_df$filename); print(files)
		txi        <- tximport(files, type = "salmon", tx2gene = tx2gene)
		
		#----- change levels
		level_cols <- {level_list}
		for (col in names(level_cols)) {{
			sample_df[,col] <- factor(sample_df[,col], levels = level_cols[[col]])
		}}
		
		#----- import txi in DESeq2
		dds <- DESeqDataSetFromTximport(txi, colData = sample_df, design = {DESIGN})
		
		#----- save as rds
		saveRDS(dds, file="{output}")
		""")
		
		with open(log.r_script, "w") as f: f.write(snakemake_format(script))
		shell("Rscript --vanilla '{log.r_script}' &> '{log.r_output}'")

##-------------------- DESeq2 -------------------------------------------------------------------------------

rule DESeq2:
	""" run DESeq2 on a count matrix """
	input:
		pph.choose_input(choice_name = "mapping", options = [
		dict(step = "import_gene_counts",   extension = "rds", contrast = "all"),
		dict(step = "import_featurecounts", extension = "rds", contrast = "all"),
		dict(step = "import_sf",            extension = "rds", contrast = "all")
		])
	output:
		pph.file_path("DESeq2", "rds", contrast = "all")
	log:
		r_script = pph.file_path("DESeq2", "R",            contrast = "all", log=True),
		r_output = pph.file_path("DESeq2", "r_output.log", contrast = "all", log=True)
	params:
		coef_names = pph.file_path("DESeq2", "coef_names.txt", contrast = "all")
	run:
		count_threshold = config["filters"]["low_counts"]
		script = textwrap.dedent(r"""
		#----- import packages
		library(DESeq2)
		
		{R_SESSION_INFO}
		
		#----- load DESeqDataSet
		dds <- readRDS("{input}")
		
		#----- pre-filtering
		keep <- rowSums(counts(dds)) >= {count_threshold}
		dds  <- dds[keep,]
		
		#----- DESeq2
		dds <- DESeq(dds, test="Wald")
		
		#----- save as rds
		saveRDS(dds, file="{output}")
		writeLines(resultsNames(dds), "{params.coef_names}")
		""")
		with open(log.r_script, "w") as f: f.write(snakemake_format(script))
		shell("Rscript --vanilla '{log.r_script}' &> '{log.r_output}'")
		
		
##-------------------- contrasts ----------------------------------------------------------------------------

rule contrast:
	""" make a contrast """
	input:
		pph.file_path("DESeq2", "rds", contrast = "all")
	output:
		pph.file_path("contrast", "rds")
	log:
		r_script = pph.file_path("contrast", "R",            log=True),
		r_output = pph.file_path("contrast", "r_output.log", log=True),
		yaml     = pph.file_path("contrast", "yaml",         log=True)
	params:
		ma_plot    = pph.file_path("contrast", "ma.pdf"),
		count_plot = pph.file_path("contrast", "counts.pdf"),
		annot_pkg  = config["organism"]["R"]["annotations"]
	run:
		contrast = pph.get_contrast(wildcards.contrast)
		with open(log.yaml, "w") as f: yaml.dump(contrast, f, default_flow_style=False)
		
		if not "r_contrast" in contrast:
			column, numerator, denominator = (contrast[key] for key in ["column", "numerator", "denominator"])
			r_contrast  = 'c("{}","{}","{}")'.format(column, numerator, denominator)
			apeglm_coef = "{}_{}_vs_{}".format(column, numerator, denominator)
		else:
			r_contrast  = apeglm_coef = contrast["r_contrast"]
                        column      =               contrast["column"]
                        numerator   =               ""
                        denominator =               ""
			
		cutoff_FDR           =           contrast["max_p_adj"]
		lfcThreshold         =           contrast["results_parameters"]["lfcThreshold"]
		altHypothesis        =           contrast["results_parameters"]["altHypothesis"]
		independentFiltering = "TRUE" if contrast["results_parameters"]["independentFiltering"] else "FALSE"
		lfc_shrink_type      =           contrast["lfcShrink_parameters"]["type"]
		rank_by              =           contrast["ranking_by"]
		rank_order           =           contrast["ranking_order"].replace("x", "res$"+rank_by)
		
		script = textwrap.dedent(r"""
		#----- import packages
		library(DESeq2)
		library(AnnotationDbi)
		library({params.annot_pkg})
		
		{R_SESSION_INFO}
		
		#----- load DESeqDataSet
		dds <- readRDS("{input}")
		
		#----- contrast
		if ("{lfc_shrink_type}"!="apeglm"){{
			res <- results(dds, contrast={r_contrast}, alpha={cutoff_FDR}, 
					lfcThreshold={lfcThreshold}, altHypothesis="{altHypothesis}", 
					independentFiltering={independentFiltering})
		}}
					
		if ("{lfc_shrink_type}"!="none"){{
			if ("{lfc_shrink_type}"=="apeglm"){{
				dds${column} <- relevel(dds${column}, ref = "{denominator}")
				dds <- nbinomWaldTest(dds)
				res <- results(dds, alpha={cutoff_FDR}, lfcThreshold={lfcThreshold}, 
						altHypothesis="{altHypothesis}", independentFiltering={independentFiltering})
				res <- lfcShrink(dds, res=res, coef="{column}_{numerator}_vs_{denominator}", 
						lfcThreshold={lfcThreshold}, type="apeglm")
			}} else {{
				res <- lfcShrink(dds, res=res, contrast={r_contrast}, 
						lfcThreshold={lfcThreshold}, type="{lfc_shrink_type}")
			}}
		}}
		
		#----- ranking
		res <- res[order({rank_order}),]
		
		#----- annotation
		res$symbol <- mapIds({params.annot_pkg}, keys=sub("\\.[0-9]+$", "", row.names(res)), column="SYMBOL", keytype="ENSEMBL", multiVals="first")
		res$entrez <- mapIds({params.annot_pkg}, keys=sub("\\.[0-9]+$", "", row.names(res)), column="ENTREZID", keytype="ENSEMBL", multiVals="first")
		
		#----- save as rds
		saveRDS(res, file="{output}")
		
		#----- MA plot
		pdf("{params.ma_plot}")
		plotMA(res, ylim=c(-2,2))
		dev.off()
		
		#----- count plot
		pdf("{params.count_plot}")
		plotCounts(dds, gene=which.min(res$padj), intgroup="{column}")
		dev.off()
		""")
		
		with open(log.r_script, "w") as f: f.write(snakemake_format(script))
		shell("Rscript --vanilla '{log.r_script}' &> '{log.r_output}'")


##-------------------- functional annotation ----------------------------------------------------------------

rule goseq:
	""" functional annotation with goseq producing GO and KEGG lists """
	input:
		txdb = pph.file_path("TxDb_from_GTF", "sqlite", contrast = "all"),
		res  = pph.file_path("contrast", "rds")
	output:
		go   = pph.file_path(step = "goseq", extension = "go.rds"),
		kegg = pph.file_path(step = "goseq", extension = "kegg.rds")
	log:
		r_script = pph.file_path(step = "goseq", extension = "R",            log=True),
		r_output = pph.file_path(step = "goseq", extension = "r_output.log", log=True),
		yaml     = pph.file_path(step = "goseq", extension = "yaml",         log=True)
	params:
		annot_pkg = config["organism"]["R"]["annotations"],
		fit_pwf   = pph.file_path(step = "goseq", extension = "pwf_fit.pdf")
	run:
		contrast = pph.get_contrast(wildcards.contrast)
		with open(log.yaml, "w") as f: yaml.dump(contrast, f, default_flow_style=False)
		
		fdr_threshold = contrast["GO"]["fdr_threshold"]
		AnnotationDbi_prefix = ".".join(params.annot_pkg.split(".")[:-1])
		
		script = textwrap.dedent(r"""
		#----- import packages
		library(goseq)
		library(GenomicFeatures)
		library(AnnotationDbi)
		library({params.annot_pkg})
		
		{R_SESSION_INFO}
		
		#----- load results
		res <- readRDS("{input.res}")
		
		#----- vector for goseq
		assayed.genes <- rownames(res)
		de.genes <- assayed.genes[which(res$padj < {fdr_threshold})]
		gene.vector <- as.integer(assayed.genes %in% de.genes); names(gene.vector) <- assayed.genes
                names(gene.vector) <- sub("\\.[0-9]+", "", names(gene.vector))
		
		#----- get gene lengths
		TxDb <- loadDb(file = "{input.txdb}")
		lengthData <- median(width(transcriptsBy(TxDb, "gene")))[rownames(res)]; names(lengthData) <- rownames(res)
		
		#----- get GO mapping
		en2eg <- as.list({AnnotationDbi_prefix}ENSEMBL2EG); go2eg <- as.list({AnnotationDbi_prefix}GO2ALLEGS)
		eg2go <- split(rep(names(go2eg), lengths(go2eg)), unlist(go2eg)); eg2kegg <- as.list({AnnotationDbi_prefix}PATH)

		grepAnnot <- function(id,mapkeys) unique(unlist(mapkeys[id], use.names=FALSE))
		go <- lapply(en2eg, grepAnnot, eg2go); kegg <- lapply(en2eg, grepAnnot, eg2kegg)
		
		#----- run goseq
		pdf("{params.fit_pwf}")
		pwf <- nullp(gene.vector, bias.data=lengthData)
		dev.off()
		GO <- goseq(pwf, gene2cat=go)
		KEGG <- goseq(pwf, gene2cat=kegg)
		
		GO$over_represented_qvalue <- p.adjust(GO$over_represented_pvalue, method="BH")
		GO$under_represented_qvalue <- p.adjust(GO$under_represented_pvalue, method="BH")
		KEGG$over_represented_qvalue <- p.adjust(KEGG$over_represented_pvalue, method="BH")
		KEGG$under_represented_qvalue <- p.adjust(KEGG$under_represented_pvalue, method="BH")
		
		#----- save as rds
		saveRDS(GO, file="{output.go}"); saveRDS(KEGG, file="{output.kegg}")
		""")
		
		with open(log.r_script, "w") as f: f.write(snakemake_format(script))
		shell("Rscript --vanilla '{log.r_script}' &> '{log.r_output}'")

		
##-------------------- QC steps -----------------------------------------------------------------------------

rule countMatrix_heatmap:
	""" plot count matrix as a heatmap """
	input:
		pph.file_path("DESeq2", "rds", contrast = "all")
	output:
		pph.file_path("countMatrix_heatmap", "pdf", contrast = "all")
	log:
		r_script = pph.file_path("countMatrix_heatmap", "R",            contrast = "all", log=True),
		r_output = pph.file_path("countMatrix_heatmap", "r_output.log", contrast = "all", log=True)
	run:
		annot  = "c({})".format(",".join('"'+s+'"' for s in config["QC"]["countMatrix_heatmap"]["annotation_col"]))
		transf = config["QC"]["countMatrix_heatmap"]["transform_type"]
		script = snakemake_format(textwrap.dedent(r"""
		#----- import packages
		library(DESeq2)
		library(pheatmap)
		
		{R_SESSION_INFO}
		
		#----- load DESeqDataSet
		dds <- readRDS("{input}")
		
		#----- transform data
		if ("{transf}"=="normTransform") {{
			dds_trans <- normTransform(dds) 
		}} else if ("{transf}"=="vst") {{
			dds_trans <- vst(dds, blind=FALSE) 
		}} else {{ 
			dds_trans <- rlog(dds, blind=FALSE)
		}}
		
		#----- plot heatmap
		select <- order(rowMeans(counts(dds,normalized=TRUE)), decreasing=TRUE)
		df <- as.data.frame(colData(dds)[,{annot}])
		pdf("{output}")
		pheatmap(assay(dds_trans)[select,], cluster_rows=FALSE, show_rownames=FALSE, cluster_cols=FALSE, annotation_col=df)
		dev.off()
		"""))
		with open(log.r_script, "w") as f: f.write(script)
		shell("Rscript --vanilla '{log.r_script}' &> '{log.r_output}'")
	
	
rule sample_similarity:
	""" plot sample similarity as a heatmap """
	input:
		pph.file_path("DESeq2", "rds", contrast = "all")
	output:
		pph.file_path("sample_similarity", "png", contrast = "all")
	log:
		r_script = pph.file_path("sample_similarity", "R",            contrast = "all", log=True),
		r_output = pph.file_path("sample_similarity", "r_output.log", contrast = "all", log=True)
	run:
		annot  = ", ".join("dds_trans$"+s for s in config["QC"]["sample_similarity"]["annotation_col"])
		transf = config["QC"]["sample_similarity"]["transform_type"]
		script = snakemake_format(textwrap.dedent(r"""
		#----- import packages
		library(DESeq2)
		library(pheatmap)
		library(RColorBrewer)
		
		{R_SESSION_INFO}
		
		#----- load DESeqDataSet
		dds <- readRDS("{input}")
		
		#----- transform data
		if ("{transf}"=="normTransform") {{
			dds_trans <- normTransform(dds) 
		}} else if ("{transf}"=="vst") {{
			dds_trans <- vst(dds, blind=FALSE) 
		}} else {{ 
			dds_trans <- rlog(dds, blind=FALSE)
		}}
		
		#----- plot heatmap
		sampleDists <- dist(t(assay(dds_trans)))
		sampleDistMatrix <- as.matrix(sampleDists)
		rownames(sampleDistMatrix) <- do.call(paste, list({annot}, sep="-"))
		colnames(sampleDistMatrix) <- NULL
		colors <- colorRampPalette( rev(brewer.pal(9, "Blues")) )(255)
		png("{output}")
		pheatmap(sampleDistMatrix, clustering_distance_rows=sampleDists, clustering_distance_cols=sampleDists, col=colors)
		dev.off()
		"""))
		with open(log.r_script, "w") as f: f.write(script)
		shell("Rscript --vanilla '{log.r_script}' &> '{log.r_output}'")
		
rule samples_pca:
	""" plot PCA of sample similarity """
	input:
		pph.file_path("DESeq2", "rds", contrast = "all")
	output:
		pph.file_path("samples_pca", "pdf", contrast = "all")
	log:
		r_script = pph.file_path("samples_pca", "R",            contrast = "all", log=True),
		r_output = pph.file_path("samples_pca", "r_output.log", contrast = "all", log=True)
	run:
		annot  = "c({})".format(", ".join('"'+s+'"' for s in config["QC"]["samples_pca"]["annotation_col"]))
		transf = config["QC"]["samples_pca"]["transform_type"]
		script = snakemake_format(textwrap.dedent(r"""
		#----- import packages
		library(DESeq2)
		
		{R_SESSION_INFO}
		
		#----- load DESeqDataSet
		dds <- readRDS("{input}")
		
		#----- transform data
		if ("{transf}"=="normTransform") {{
			dds_trans <- normTransform(dds) 
		}} else if ("{transf}"=="vst") {{
			dds_trans <- vst(dds, blind=FALSE) 
		}} else {{ 
			dds_trans <- rlog(dds, blind=FALSE)
		}}
		
		#----- plot PCA
		pdf("{output}")
		plotPCA(dds_trans, intgroup={annot})
		dev.off()
		"""))
		with open(log.r_script, "w") as f: f.write(script)
		shell("Rscript --vanilla '{log.r_script}' &> '{log.r_output}'")


##-------------------- report -------------------------------------------------------------------------------

rule report:
	""" write a static Rmd report """
	input:
		get_inputs_all()
	output:
		pph.file_path("report", "Rmd", contrast = "all")
	run:
		file_table  = pph.file_path("report", "tsv", contrast = "all")
		pph.log_generated_files(save_to = file_table)
		
		rt = ReportTool(config, id_dicts={"contrast": pph.get_contrast_id_dict()})
		report_text = rt.generate_report()
		
		# switch single and double braces
		report_text = report_text.replace("{","{{").replace("}","}}")
		report_text = report_text.replace("{{{{","{").replace("}}}}","}")
		
		# fill in wildcards
		report_wildcards  = re.findall("(?<!{){([^{}]+)}(?!})", report_text)
		format_dict = {}
		for rw in report_wildcards:
			parts = rw.split("-")
			if len(parts) == 2:
				format_dict[rw] = pph.file_path(parts[0], parts[1], contrast = "all")
			elif len(parts) == 3:
				format_dict[rw] = pph.file_path(parts[0], parts[1], contrast = parts[2])
			else:
				format_dict[rw] = "{" + rw + "}"
					
		format_dict["WORKING_DIRECTORY"] = os.getcwd() + os.sep
		format_dict["R_COMMON"]          = str(rt.report_snippet_base_dir/"R_common")
		format_dict["FILE_TABLE"]        = file_table
				
		report_text = report_text.format(**format_dict)
		report_text = report_text.replace("{{","{").replace("}}","}")
		
		with open(output[0], "w") as f:
			f.write(report_text)





