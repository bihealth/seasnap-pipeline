## SeA-SnaP single cell pipeline for RNA-seq analysis
## version: 0.1
## author: J.P.Pett (patrick.pett@bihealth.de)

import os, sys, yaml, re, textwrap, pandas as pd
from collections import OrderedDict
from time import asctime, localtime, time
from pathlib import Path
from snakemake.utils import report, format as snakemake_format, min_version
from snakemake.logging import logger
from tools.pipeline_tools import MappingPipelinePathHandler

yaml.add_representer(OrderedDict, lambda dumper, data: dumper.represent_dict(dict(data)))
min_version("3.7")
shell.prefix("set -e  pipefail;")

# source files
SNAKEDIR  = Path(workflow.current_basedir)
SNAKEFILE = workflow.snakefile
SCRIPTDIR = str(SNAKEDIR / "external_scripts")

# assemble config
configfile: str(SNAKEDIR / "defaults" / "sc_config_defaults.yaml")
configfile: "sc_config.yaml"
configfile: "sample_info.yaml"
if config["organism_defaults"]:
	configfile: str(SNAKEDIR / "defaults" / config["organism_defaults"])
	configfile: "sc_config.yaml"

# create path handler
conf_ranges = str(SNAKEDIR / "defaults" / "sc_config_ranges.yaml")
test_config = conf_ranges if config["pipeline_param"]["test_config"] else None
pph = MappingPipelinePathHandler(workflow, test_config)

# link indices
pph.link_index(step="cellranger_count", fix="all", subdir="outdir", add_done=True)

# exclude symbols '.' and '/' from wildcards
wildcard_constraints: 
	sample="[^./]+",
	mate  ="[^./]+"

onstart:
	# draw a dag
	dag_file = pph.file_path(step="pipeline_report", extension="rule_execution.png", fix="all")
	os.makedirs(os.path.dirname(dag_file), exist_ok=True)
	shell("snakemake --quiet --snakefile {} --rulegraph | dot -Tpng > {}".format(SNAKEFILE, dag_file))
	# info about the pipeline run
	info_file = pph.file_path(step="pipeline_report", extension="summary.csv", fix="all")
	os.makedirs(os.path.dirname(info_file), exist_ok=True)
	shell("snakemake --quiet --snakefile {} --summary | sed 's/\t/, /g' > {}".format(SNAKEFILE, info_file))
	# save merged config
	config_file = pph.file_path(step="pipeline_report", extension="yaml", fix="all")
	with open(config_file, "w") as f: yaml.dump(config, f, default_flow_style=False)
	# warnings
	#mapping_choices, qc_choices = (config["pipeline_param"][key] for key in ["mapping_results", "QC_results"])
	#for qc_step in ["dupradar", "infer_experiment", "rna_seqc", "qualimap", "qc"]:
	#	if qc_step in qc_choices and "star-gene_counts" not in mapping_choices:
	#		logger.warning("{}: cannot run, because 'star-gene_counts' was not selected as mapping output".format(qc_step))

##-------------------- starting point ----------------------------------------------------------------------

def get_inputs_all():
	inputs = []

	#inputs += pph.expand_path("cellranger_count", "done", flowcell="all_flowcells", lane="all_lanes", mate="all_mates", library="all_libraries")
	inputs += [pph.file_path("velocyto_run", "loom", fix="all")]

	return inputs


shell("rm -f {}".format(pph.file_path(step="pipeline_report", fix="all")))

rule all:
	input:
		get_inputs_all()
	output:
		html = pph.file_path(step="pipeline_report", extension="report.html", fix="all")
	run:
		loctime = asctime(localtime(time()))
		rule_execution = pph.file_path("pipeline_report", "rule_execution.png", fix="all")
		summary        = pph.file_path("pipeline_report", "summary.csv",        fix="all")
		version_info   = pph.file_path("pipeline_report", "version_info.txt",   fix="all")
		conda_info     = pph.file_path("pipeline_report", "conda_info.txt",     fix="all")
		dag = rule_execution.split("/")[-1]
		shell("conda list > {}".format(version_info))
		shell("conda info > {}".format(conda_info))
		report("""
		===========================
		RNAseq single cell pipeline
		===========================
		
		**Finished: {loctime}**
		
		.. image:: {dag}
		
		File status at pipeline start:
		==============================
		
		.. csv-table::
			:file: {summary}
			
		Version info:
		=============
		
		.. include:: {version_info}
			:literal:
		
		Conda info:
		===========
		
		.. include:: {conda_info}
			:literal:
		
		""", output.html, graph = rule_execution, table = summary)
		
rule export:
	input:
		get_inputs_all()
	run:
		pph.export()

##-------------------- CellRanger -------------------------------------------------------------------------------

rule cellranger_count:
    """ run cellranger count """
	input:
		reads = lambda wildcards: pph.get_fastq_pairs(wildcards, mate="*"),
		transcriptome = config["organism"]["files"]["cellranger_transcriptome"]
	output:
		outdir = directory(pph.out_dir_name(step="cellranger_count")+"/outdir"),
		links  = directory(pph.out_dir_name(step="cellranger_count")+"/input_links"),
	log:
		out = pph.file_path(step = "cellranger_count", extension="output.log", log=True)
	params:
		options = config["rule_options"]["cellranger_count"]["cmd_opt"]
	run:
		dirnames = ",".join(os.path.dirname(p) for p in input.reads)
		basenames = ",".join(os.path.basename(p) for p in input.reads)

		script = textwrap.dedent(r"""
		#----- prepare
		set -eux
		cellranger --version

		#----- collect input links
		mkdir {output.links}
		ln -s {input.reads} {output.links}

		#----- Cellranger counting
		cellranger count \
		  --id={output.outdir} \
		  --fastqs={output.links} \
		  --sample='' \
		  --transcriptome={input.transcriptome} \
		  {params.options}
		""")

		script_file = pph.log(log.out, snakemake_format(script), step="cellranger_count", extension="sh", **wildcards)
		shell("bash '{script_file}' &>> '{log.out}'")

##-------------------- Velocyto -------------------------------------------------------------------------------

rule velocyto_run:
    """ run velocyto on 10X Chromium samples """
	input:
		gtf = config["organism"]["files"]["cellranger_gtf"],
		mask = config["organism"]["files"]["velocyto_mask_gtf"],
		cellranger_done = pph.file_path(step="cellranger_count", extension="done")
	output:
		pph.file_path(step="velocyto_run", extension="loom")
	log:
		out = pph.file_path(step="velocyto_run", extension="output.log", log=True)
	params:
	    cellranger_outdir = pph.out_dir_name(step="cellranger_count")+"/outdir",
	    options = config["rule_options"]["velocyto_run"]["cmd_opt"]
	run:	
		mask = f"-m {input.mask}" if input.mask else ""
		script = textwrap.dedent(r"""
		#----- prepare
		set -eux
		velocyto --version

		#----- run velocyto
		#velocyto run10x \
		#{params.cellranger_outdir} \
		#{input.gtf} \
		#{params.options}
		velocyto run -b {params.cellranger_outdir}/filtered_feature_bc_matrix/barcodes.tsv {mask} -o $(dirname {output}) {params.options} {params.cellranger_outdir}/possorted_genome_bam.bam {input.gtf}

		#----- move results
		mv $(dirname {output})/*.loom {output}
		""")

		script_file = pph.log(log.out, snakemake_format(script), step="velocyto_run", extension="sh", **wildcards)
		shell("bash '{script_file}' &>> '{log.out}'")

##-------------------- jupyter nb -------------------------------------------------------------------------------

rule create_ipynb:
	""" compile a jupyter notebook for second line analysis """
	input:
		get_inputs_all()
	output:
		pph.file_path("create_ipynb", "ipynb", fix="all")
	run:
		rt = ReportTool(pph, profile="sc_analysis")
		report_text = rt.generate_report()

		text_sub = dict(file_tab="", config="")
		for tag, num, path in ((tag, num, path) for tag, paths in rt.use_results.items() for num, path in enumerate(paths)):
			file_table  = pph.file_path("create_ipynb",  "tsv", fix="all", path_pattern=path)
			config_file = pph.file_path("pipeline_report", "yaml", fix="all", path_pattern=path)
			pph.log_generated_files(save_to=file_table, path_pattern=path)

			id_suffix, _ = rt.get_id_suffix(tag, num)
			text_sub["file_tab"] += (f'file_tab{id_suffix} <- data.frame(read.table("{file_table}", sep="\\t", header=TRUE))\n'
			                         f'file_tab{id_suffix}$filename <- as.character(file_tab{id_suffix}$filename)\n')
			text_sub["config"]   += f'config{id_suffix} <- yaml.load_file("{config_file}")\n'

		report_text = report_text.replace("{{WORKING_DIRECTORY}}", os.getcwd() + os.sep)
		report_text = report_text.replace("{{R_COMMON}}", str(rt.report_snippet_base_dir/"R_common"))
		report_text = report_text.replace("{{LOAD_FILE_TABLE}}", text_sub["file_tab"])
		report_text = report_text.replace("{{LOAD_CONFIG_FILE}}", text_sub["config"])

		with open(output[0], "w") as f: f.write(report_text)